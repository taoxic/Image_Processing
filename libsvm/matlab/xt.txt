`svm-train' Usage svm-train的使用
=================

Usage: svm-train [options] training_set_file [model_file]
options:
设置svm的类型
-s svm_type : set type of SVM (default 0)
	0 -- C-SVC		(multi-class classification)
	1 -- nu-SVC		(multi-class classification)
	2 -- one-class SVM	
	3 -- epsilon-SVR	(regression)
	4 -- nu-SVR		(regression)
设置核函数的类型
-t kernel_type : set type of kernel function (default 2)
	0 -- linear: u'*v
	1 -- polynomial: (gamma*u'*v + coef0)^degree
	2 -- radial basis function: exp(-gamma*|u-v|^2)
	3 -- sigmoid: tanh(gamma*u'*v + coef0)
	4 -- precomputed kernel (kernel values in training_set_file)
-d degree : set degree in kernel function (default 3)
-g gamma : set gamma in kernel function (default 1/num_features)
-r coef0 : set coef0 in kernel function (default 0)
-c cost : set the parameter C of C-SVC, epsilon-SVR, and nu-SVR (default 1)
-n nu : set the parameter nu of nu-SVC, one-class SVM, and nu-SVR (default 0.5)
-p epsilon : set the epsilon in loss function of epsilon-SVR (default 0.1)
-m cachesize : set cache memory size in MB (default 100)
-e epsilon : set tolerance of termination criterion (default 0.001)
-h shrinking : whether to use the shrinking heuristics, 0 or 1 (default 1)
-b probability_estimates : whether to train a SVC or SVR model for probability estimates, 0 or 1 (default 0)
-wi weight : set the parameter C of class i to weight*C, for C-SVC (default 1)
-v n: n-fold cross validation mode
-q : quiet mode (no outputs)


The k in the -g option means the number of attributes in the input data.

option -v randomly splits the data into n parts and calculates cross
validation accuracy/mean squared error on them.

Options：可用的选项即表示的涵义如下
　　-s svm类型：SVM设置类型(默认0)

　　0 -- C-SVC ：C-支持向量分类机；参数C为惩罚系数，适当的参数C对分类Accuracy很关键。

　　1 --v-SVC ：v-支持向量分类机；由于C的选取比较困难，用另一个参数v代替C。C是“无意义”的，
v是有意义的。（book：《DM中的新方法--SVM》中说的非常详细）
　　2 C 一类SVM ：单类别-支持向量机
　　3 -- e -SVR
　　4 -- v-SVR
　　-t 核函数类型：核函数设置类型(默认2)
　　0 C 线性：u'v
　　1 C 多项式：(r*u'v + coef0)^degree
　　2 C RBF函数：exp(-gamma|u-v|^2)
　　3 Csigmoid：tanh(r*u'v + coef0)
　　-d degree：核函数中的degree设置(针对多项式核函数)(默认3)
　　-g r(gama)：核函数中的gamma函数设置(针对多项式/rbf/sigmoid核函数)(默认

1/ k)
　　-r coef0：核函数中的coef0设置(针对多项式/sigmoid核函数)((默认0)

　　-c cost：设置C-SVC，e -SVR和v-SVR的参数(损失函数)(默认1)

　　-n nu：设置v-SVC，一类SVM和v- SVR的参数(默认0.5)
　　-p p：设置e -SVR 中损失函数p的值(默认0.1)
　　-m cachesize：设置cache内存大小，以MB为单位(默认40)
　　-e eps：设置允许的终止判据(默认0.001)
　　-h shrinking：是否使用启发式，0或1(默认1)

　　-wi weight：设置第几类的参数C为weight*C(C-SVC中的C)(默认1)
　　-v n: n-fold交互检验模式，n为fold的个数，必须大于等于2
　　其中-g选项中的k是指输入数据中的属性数。option -v 随机地将数据剖分为n部

分并计算交互检验准确度和均方根误差。以上这些参数设置可以按照SVM的类型和核函

数所支持的参数进行任意组合，如果设置的参数在函数或SVM类型中没有也不会产生影

响，程序不会接受该参数；如果应有的参数设置不正确，参数将采用默认值。




model

odel =
Parameters: [5x1 double]
nr_class: 2
totalSV: 259 % 支持向量的数目
rho: 0.0514 % b
Label: [2x1 double] % classification中标签的个数
ProbA: []
ProbB: []%使用-b参数时才能用到，用于概率估计
nSV: [2x1 double] % 每类支持向量的个数
sv_coef: [259x1 double] % 支持向量对应的Wi,支持向量在决策函数中的系数
SVs: [259x13 double] % 装的是259个支持向量

model.Parameters参数意义从上到下依次为：
-s svm类型：SVM设置类型(默认0)
-t 核函数类型：核函数设置类型(默认2)
-d degree：核函数中的degree设置(针对多项式核函数)(默认3)
-g r(gama)：核函数中的gamma函数设置(针对多项式/rbf/sigmoid核函数) (默认类别数目的倒数)
-r coef0：核函数中的coef0设置(针对多项式/sigmoid核函数)((默认0)





处理多类分类问题libsvm用的是one- versus-one法：
    一对一法（one-versus-one,简称OVO SVMs或者pairwise）。其做法是在任意两类样本之间
设计一个SVM，因此k个类别的样本就需要设计k(k-1)/2个SVM。当对一个未知样本 进行分类时，
最后得票最多的类别即为该未知样本的类别。Libsvm中的多类分类就是根据这个方法实现的。
    还是假设有四类A,B,C,D 四类。在训练的时候我选择A,B; A,C; A,D; B,C; B,D;C,D所对应的向量作为训练集，
然后得到六个训练结果，在测试的时候，把对应的向量分别对六个结果进行测试，然后采取投票形式，
最后得到一组结果。



函数中调用过程如下：

svm_train-->svm_train_one-->solve_c_svc(for example)-->s.Solve
经过训练后得到model，其中包括了k*(k-1)/2个分类器的判别函数

svm_predict-->svm_predict_values-->Kernel::k_function
通过判别函数进行投票，产生决策结果





























